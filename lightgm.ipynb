{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0791cb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 887226, number of negative: 883232\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.804177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17682\n",
      "[LightGBM] [Info] Number of data points in the train set: 1770458, number of used features: 138\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501128 -> initscore=0.004512\n",
      "[LightGBM] [Info] Start training from score 0.004512\n",
      "Accuracy: 0.5409757916021825\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.52      0.61    312179\n",
      "           1       0.34      0.60      0.44    130436\n",
      "\n",
      "    accuracy                           0.54    442615\n",
      "   macro avg       0.55      0.56      0.52    442615\n",
      "weighted avg       0.63      0.54      0.56    442615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PERFORM LIGHTGM MODEL ..........\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# FUNTION TO HANDLE OUTLIERS \n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# TIME BASED FEATURE ENG..........\n",
    "def time_based_features(df):\n",
    "    df['date_id'] = pd.to_datetime(df['date_id'], format='%Y-%m-%d')\n",
    "    df['day_of_week'] = df['date_id'].dt.dayofweek\n",
    "    df['month'] = df['date_id'].dt.month\n",
    "    df['year'] = df['date_id'].dt.year\n",
    "    df['hour_of_day'] = (df['seconds_in_bucket'] / 3600).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# PRICE BADES FEATURE ENG .........\n",
    "def price_based_features(df):\n",
    "    \n",
    "    df['price_spread'] = df['ask_price'] - df['bid_price']\n",
    "  \n",
    "    df['price_ratio'] = df['ask_price'] / df['bid_price']\n",
    "    \n",
    "    \n",
    "    \n",
    "    df['price_pct_change_5'] = df.groupby('stock_id')['reference_price'].pct_change(periods=5)\n",
    "    df['price_pct_change_10'] = df.groupby('stock_id')['reference_price'].pct_change(periods=10)\n",
    "    df['price_pct_change_30'] = df.groupby('stock_id')['reference_price'].pct_change(periods=30)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# VOLUME BASED FEATURE ENG...\n",
    "def volume_based_features(df):\n",
    "    df['volume_spread'] = df['ask_size'] - df['bid_size']\n",
    "    \n",
    "    df['volume_ratio'] = df['ask_size'] / df['bid_size']\n",
    "    \n",
    "    df['volume_pct_change'] = df.groupby('stock_id')['matched_size'].pct_change()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# PEFORM IMBALANCED BASE FEATURE ENG......\n",
    "def imbalance_features(df):\n",
    "    # CRATE A FEATURE THAT CAPTURE THE RELATIONSHIP BETWEEN imbalance_size AND  imbalance_buy_sell_flag\n",
    "    df['imbalance_relation'] = df['imbalance_size'] * (df['imbalance_buy_sell_flag'] == 'B') - df['imbalance_size'] * (df['imbalance_buy_sell_flag'] == 'S')\n",
    "    \n",
    "    \n",
    "    # COMPUTE COMPULATIVE  IMBALANCE FEATURE OVER TIME \n",
    "    df['cumulative_imbalance_size'] = df.groupby(['stock_id', 'time_id'])['imbalance_size'].cumsum()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# FUNCTION TO PERFORM MOVING AVERAGE  AND EXPONENTIAL MOVING AVERAGE   \n",
    "\n",
    "def moving_averages_ema(df):\n",
    "    \n",
    "    # CALCULATE MOVING AVERAGE  FOR PRICE  AND VOLUME RELATED COLUMNS OVER DIFFERENT TIME WINDOW \n",
    "    windows = [5, 10, 30]  # TIME WINDOW FOR MOVING AVERAGE \n",
    "    for window in windows:\n",
    "        df[f'price_ma_{window}'] = df.groupby('stock_id')['wap'].transform(lambda x: x.rolling(window).mean())\n",
    "        df[f'volume_ma_{window}'] = df.groupby('stock_id')['volume_spread'].transform(lambda x: x.rolling(window).mean())\n",
    "    \n",
    "    # CALCULATE THE EXPONENETIAL MOVING AVERAGE  \n",
    "    alpha = [0.1, 0.2, 0.5]  # ALPHA VALUES FOR EMA \n",
    "    for a in alpha:\n",
    "        df[f'price_ema_{a}'] = df.groupby('stock_id')['wap'].transform(lambda x: x.ewm(alpha=a, adjust=False).mean())\n",
    "        df[f'volume_ema_{a}'] = df.groupby('stock_id')['volume_spread'].transform(lambda x: x.ewm(alpha=a, adjust=False).mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# FUNTION TO PERFORM PRICE TRENDS FEATURE ENGINNERRING \n",
    "def price_trends(df):\n",
    "    periods = [5, 10, 30]  # NUMBER OF PREVIOUS TIME PERIODS\n",
    "    for period in periods:\n",
    "        df[f'price_trend_{period}'] = (df.groupby('stock_id')['reference_price'].shift(0) - df.groupby('stock_id')['reference_price'].shift(period)) > 0\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# FUNTION TO CALCULATE KURTOSIS\n",
    "def calculate_kurtosis(grouped_data):\n",
    "    return grouped_data.kurtosis()\n",
    "\n",
    "# FUNCTION TO CALCULATE STATISTICAL MEATURES\n",
    "def calculate_statistics(df):\n",
    "    # DEFINE NUMERIC COL\n",
    "    numerical_cols = [\n",
    "        'seconds_in_bucket', 'imbalance_size', 'reference_price', 'matched_size',\n",
    "        'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'target'\n",
    "    ]\n",
    "\n",
    "    # CALCULATE STATISTICS FOR EACH NUMERIC COLUMN\n",
    "    for col in numerical_cols:\n",
    "        df[f'{col}_mean'] = df.groupby('stock_id')[col].transform('mean')\n",
    "        df[f'{col}_std'] = df.groupby('stock_id')[col].transform('std')\n",
    "        df[f'{col}_skew'] = df.groupby('stock_id')[col].transform('skew')\n",
    "        df[f'{col}_kurtosis'] = df.groupby('stock_id')[col].transform(calculate_kurtosis)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DATASET\n",
    "df_train = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\predict us stock price movement compitetion\\train.csv\")\n",
    "\n",
    "# FEATURE \n",
    "columns_to_keep = [\n",
    "    'stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag',\n",
    "    'reference_price', 'matched_size', 'far_price', 'near_price', 'bid_price', 'bid_size',\n",
    "    'ask_price', 'ask_size', 'wap', 'target', 'time_id', 'row_id'\n",
    "]\n",
    "df_train = df_train[columns_to_keep]\n",
    "\n",
    "# DEFINE CATEGORICAL AND NUMERIC COLUMN\n",
    "categorical_cols = [\n",
    "    'stock_id', 'date_id', 'imbalance_buy_sell_flag', 'time_id', 'row_id'\n",
    "]\n",
    "numerical_cols = [\n",
    "    'seconds_in_bucket', 'imbalance_size', 'reference_price', 'matched_size',\n",
    "    'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'target'\n",
    "]\n",
    "\n",
    "#IDENTIFY MISSING VALIES WITH IMPUTE \n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_train[['target']] = imputer.fit_transform(df_train[['target']])\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# HANDLE OUTLIERS \n",
    "df_train = handle_outliers(df_train, 'target')\n",
    "\n",
    "\n",
    "\n",
    "df_train = time_based_features(df_train)\n",
    "df_train = price_based_features(df_train)\n",
    "df_train = volume_based_features(df_train)\n",
    "df_train = imbalance_features(df_train)\n",
    "df_train = moving_averages_ema(df_train)\n",
    "df_train = price_trends(df_train)\n",
    "df_train = calculate_statistics(df_train)\n",
    "\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# PERFORM BINARY ENCODE FOR CATEGORICAL COL\n",
    "encoder = ce.BinaryEncoder(cols=categorical_cols)\n",
    "df_train_encoded = encoder.fit_transform(df_train)\n",
    "\n",
    "# NORMALIZE AND SCALEING \n",
    "scaler_train = StandardScaler()\n",
    "df_train_encoded[numerical_cols] = scaler_train.fit_transform(df_train_encoded[numerical_cols])\n",
    "\n",
    "\n",
    "# DEFINE FEATURE AND TARGET VARIABLE \n",
    "X = df_train_encoded.drop(columns=['target'])\n",
    "y = df_train_encoded['target']\n",
    "\n",
    "# SPLIT DATA INTO TRAINING AND TESTING SET \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# CREATE LIGHTGM DATASET FOR TRAINIGN \n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "# DEFINE HYPERPARAMETERS FOR LIGHTGM MODEL \n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "# TRAIN THE LIGHTGM MODEL \n",
    "num_round = 100\n",
    "bst = lgb.train(params, train_data, num_round)\n",
    "\n",
    "# PREDICTION ON THE TESTSET \n",
    "y_pred_prob = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "y_pred = [1 if p > 0.5 else 0 for p in y_pred_prob]  # Convert probabilities to binary predictions\n",
    "\n",
    "# CONVERT CONTINUOUS VALUES TO BINARY LABELS  USING A THRESHOLD\n",
    "threshold = 0.5\n",
    "y_test_binary = [1 if p > threshold else 0 for p in y_test]\n",
    "\n",
    "# EVALUATE THE MODEL WITH BINARY LABEL \n",
    "accuracy = accuracy_score(y_test_binary, y_pred)\n",
    "classification_rep = classification_report(y_test_binary, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f668c91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
