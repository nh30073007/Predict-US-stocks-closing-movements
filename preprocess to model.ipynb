{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c09a6d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         stock_id_0  stock_id_1  stock_id_2  stock_id_3  stock_id_4  \\\n",
      "5730              0           0           0           0           0   \n",
      "5731              0           0           0           0           0   \n",
      "5732              0           0           0           0           0   \n",
      "5733              0           0           0           0           0   \n",
      "5734              0           0           0           0           0   \n",
      "...             ...         ...         ...         ...         ...   \n",
      "5237975           1           0           1           0           1   \n",
      "5237976           1           0           1           0           1   \n",
      "5237977           1           0           1           0           1   \n",
      "5237978           1           0           1           0           1   \n",
      "5237979           1           1           0           0           0   \n",
      "\n",
      "         stock_id_5  stock_id_6  stock_id_7  date_id_0  date_id_1  ...  \\\n",
      "5730              0           0           1          0          0  ...   \n",
      "5731              0           1           0          0          0  ...   \n",
      "5732              0           1           1          0          0  ...   \n",
      "5733              1           0           0          0          0  ...   \n",
      "5734              1           0           1          0          0  ...   \n",
      "...             ...         ...         ...        ...        ...  ...   \n",
      "5237975           1           0           0          1          1  ...   \n",
      "5237976           1           0           1          1          1  ...   \n",
      "5237977           1           1           0          1          1  ...   \n",
      "5237978           1           1           1          1          1  ...   \n",
      "5237979           1           0           1          1          1  ...   \n",
      "\n",
      "         row_id_12  row_id_13  row_id_14  row_id_15  row_id_16  row_id_17  \\\n",
      "5730             0          0          0          0          0          0   \n",
      "5731             0          0          0          0          0          0   \n",
      "5732             0          0          0          0          0          0   \n",
      "5733             0          0          0          0          0          0   \n",
      "5734             0          0          0          0          0          0   \n",
      "...            ...        ...        ...        ...        ...        ...   \n",
      "5237975          0          0          0          0          1          1   \n",
      "5237976          0          0          0          0          1          1   \n",
      "5237977          0          0          0          0          1          1   \n",
      "5237978          0          0          0          1          0          0   \n",
      "5237979          0          0          0          1          0          0   \n",
      "\n",
      "         row_id_18  row_id_19  row_id_20  row_id_21  \n",
      "5730             0          0          0          1  \n",
      "5731             0          0          1          0  \n",
      "5732             0          0          1          1  \n",
      "5733             0          1          0          0  \n",
      "5734             0          1          0          1  \n",
      "...            ...        ...        ...        ...  \n",
      "5237975          1          1          0          1  \n",
      "5237976          1          1          1          0  \n",
      "5237977          1          1          1          1  \n",
      "5237978          0          0          0          0  \n",
      "5237979          0          0          0          1  \n",
      "\n",
      "[2219073 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "#preprocess step.....\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# FUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# DATASET\n",
    "df_train = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\predict us stock price movement compitetion\\train.csv\")\n",
    "\n",
    "# FEATURE \n",
    "columns_to_keep = [\n",
    "    'stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag',\n",
    "    'reference_price', 'matched_size', 'far_price', 'near_price', 'bid_price', 'bid_size',\n",
    "    'ask_price', 'ask_size', 'wap', 'target', 'time_id', 'row_id'\n",
    "]\n",
    "df_train = df_train[columns_to_keep]\n",
    "\n",
    "# DEFINE CATEGORICAL AND NUMERIC COLUMN\n",
    "categorical_cols = [\n",
    "    'stock_id', 'date_id', 'imbalance_buy_sell_flag', 'time_id', 'row_id'\n",
    "]\n",
    "numerical_cols = [\n",
    "    'seconds_in_bucket', 'imbalance_size', 'reference_price', 'matched_size',\n",
    "    'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'target'\n",
    "]\n",
    "\n",
    "# IDENTIFY MISSING VALUE AND IMPUTE WITH MEAN\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_train[['target']] = imputer.fit_transform(df_train[['target']])\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# HANDLE OUTLIERS\n",
    "df_train = handle_outliers(df_train, 'target')\n",
    "\n",
    "# BINARY ENCIDER FOR CATEGORICAL COLUMN\n",
    "encoder = ce.BinaryEncoder(cols=categorical_cols)\n",
    "df_train_encoded = encoder.fit_transform(df_train)\n",
    "\n",
    "# NORMALIZE AND SCALING \n",
    "scaler_train = StandardScaler()\n",
    "df_train_encoded[numerical_cols] = scaler_train.fit_transform(df_train_encoded[numerical_cols])\n",
    "\n",
    "print(df_train_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5128ec11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d89a67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         stock_id_0  stock_id_1  stock_id_2  stock_id_3  stock_id_4  \\\n",
      "5730              0           0           0           0           0   \n",
      "5731              0           0           0           0           0   \n",
      "5732              0           0           0           0           0   \n",
      "5733              0           0           0           0           0   \n",
      "5734              0           0           0           0           0   \n",
      "...             ...         ...         ...         ...         ...   \n",
      "5237975           1           0           1           0           1   \n",
      "5237976           1           0           1           0           1   \n",
      "5237977           1           0           1           0           1   \n",
      "5237978           1           0           1           0           1   \n",
      "5237979           1           1           0           0           0   \n",
      "\n",
      "         stock_id_5  stock_id_6  stock_id_7  date_id_0  date_id_1  ...  \\\n",
      "5730              0           0           1          0          0  ...   \n",
      "5731              0           1           0          0          0  ...   \n",
      "5732              0           1           1          0          0  ...   \n",
      "5733              1           0           0          0          0  ...   \n",
      "5734              1           0           1          0          0  ...   \n",
      "...             ...         ...         ...        ...        ...  ...   \n",
      "5237975           1           0           0          1          1  ...   \n",
      "5237976           1           0           1          1          1  ...   \n",
      "5237977           1           1           0          1          1  ...   \n",
      "5237978           1           1           1          1          1  ...   \n",
      "5237979           1           0           1          1          1  ...   \n",
      "\n",
      "         row_id_16  row_id_17  row_id_18  row_id_19  row_id_20  row_id_21  \\\n",
      "5730             0          0          0          0          0          1   \n",
      "5731             0          0          0          0          1          0   \n",
      "5732             0          0          0          0          1          1   \n",
      "5733             0          0          0          1          0          0   \n",
      "5734             0          0          0          1          0          1   \n",
      "...            ...        ...        ...        ...        ...        ...   \n",
      "5237975          1          1          1          1          0          1   \n",
      "5237976          1          1          1          1          1          0   \n",
      "5237977          1          1          1          1          1          1   \n",
      "5237978          0          0          0          0          0          0   \n",
      "5237979          0          0          0          0          0          1   \n",
      "\n",
      "         day_of_week  month  year  hour_of_day  \n",
      "5730               3      1  1970            0  \n",
      "5731               3      1  1970            0  \n",
      "5732               3      1  1970            0  \n",
      "5733               3      1  1970            0  \n",
      "5734               3      1  1970            0  \n",
      "...              ...    ...   ...          ...  \n",
      "5237975            3      1  1970            0  \n",
      "5237976            3      1  1970            0  \n",
      "5237977            3      1  1970            0  \n",
      "5237978            3      1  1970            0  \n",
      "5237979            3      1  1970            0  \n",
      "\n",
      "[2219073 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "#apply timebased feature engineering \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# FUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# FUNCTION TO PERFORM TIME BASED FEATURE ENGINEERING \n",
    "def time_based_features(df):\n",
    "    df['date_id'] = pd.to_datetime(df['date_id'], format='%Y-%m-%d')\n",
    "    df['day_of_week'] = df['date_id'].dt.dayofweek\n",
    "    df['month'] = df['date_id'].dt.month\n",
    "    df['year'] = df['date_id'].dt.year\n",
    "    df['hour_of_day'] = (df['seconds_in_bucket'] / 3600).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# DATASET\n",
    "df_train = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\predict us stock price movement compitetion\\train.csv\")\n",
    "\n",
    "# FEATURE\n",
    "columns_to_keep = [\n",
    "    'stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag',\n",
    "    'reference_price', 'matched_size', 'far_price', 'near_price', 'bid_price', 'bid_size',\n",
    "    'ask_price', 'ask_size', 'wap', 'target', 'time_id', 'row_id'\n",
    "]\n",
    "df_train = df_train[columns_to_keep]\n",
    "\n",
    "# DEFINE CATEGORICAL AND NUMERIC COLUMN\n",
    "categorical_cols = [\n",
    "    'stock_id', 'date_id', 'imbalance_buy_sell_flag', 'time_id', 'row_id'\n",
    "]\n",
    "numerical_cols = [\n",
    "    'seconds_in_bucket', 'imbalance_size', 'reference_price', 'matched_size',\n",
    "    'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'target'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# IDENTIFY MISSING VALUES AND IMPUTE WITH MEAN\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_train[['target']] = imputer.fit_transform(df_train[['target']])\n",
    "\n",
    "\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# HANDLE OUTLIERS\n",
    "df_train = handle_outliers(df_train, 'target')\n",
    "\n",
    "# PERFORM TIME BASED FEATURE ENGINEERING \n",
    "df_train = time_based_features(df_train)\n",
    "\n",
    "# PERFORM BINARY ENCODE FOR CATEGORICAL COLUMN\n",
    "encoder = ce.BinaryEncoder(cols=categorical_cols)\n",
    "df_train_encoded = encoder.fit_transform(df_train)\n",
    "\n",
    "# NORMALIZE AND SCALING \n",
    "scaler_train = StandardScaler()\n",
    "df_train_encoded[numerical_cols] = scaler_train.fit_transform(df_train_encoded[numerical_cols])\n",
    "\n",
    "\n",
    "print(df_train_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec1326f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c07c68d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         stock_id_0  stock_id_1  stock_id_2  stock_id_3  stock_id_4  \\\n",
      "17190             0           0           0           0           0   \n",
      "17193             0           0           0           0           0   \n",
      "17194             0           0           0           0           0   \n",
      "17195             0           0           0           0           0   \n",
      "17196             0           0           0           0           0   \n",
      "...             ...         ...         ...         ...         ...   \n",
      "5237975           0           1           1           1           0   \n",
      "5237976           1           0           0           1           1   \n",
      "5237977           0           1           1           1           0   \n",
      "5237978           0           1           1           1           0   \n",
      "5237979           1           1           0           0           0   \n",
      "\n",
      "         stock_id_5  stock_id_6  stock_id_7  date_id_0  date_id_1  ...  \\\n",
      "17190             0           0           1          0          0  ...   \n",
      "17193             0           1           0          0          0  ...   \n",
      "17194             0           1           1          0          0  ...   \n",
      "17195             1           0           0          0          0  ...   \n",
      "17196             1           0           1          0          0  ...   \n",
      "...             ...         ...         ...        ...        ...  ...   \n",
      "5237975           1           0           0          1          1  ...   \n",
      "5237976           1           1           1          1          1  ...   \n",
      "5237977           1           0           1          1          1  ...   \n",
      "5237978           1           1           0          1          1  ...   \n",
      "5237979           1           0           1          1          1  ...   \n",
      "\n",
      "         row_id_21  day_of_week  month  year  hour_of_day  price_spread  \\\n",
      "17190            1            3      1  1970            0      0.000108   \n",
      "17193            0            3      1  1970            0      0.000043   \n",
      "17194            1            3      1  1970            0      0.000281   \n",
      "17195            0            3      1  1970            0      0.000454   \n",
      "17196            1            3      1  1970            0      0.000438   \n",
      "...            ...          ...    ...   ...          ...           ...   \n",
      "5237975          1            3      1  1970            0      0.000117   \n",
      "5237976          0            3      1  1970            0      0.000257   \n",
      "5237977          1            3      1  1970            0      0.000094   \n",
      "5237978          0            3      1  1970            0      0.000240   \n",
      "5237979          1            3      1  1970            0      0.000318   \n",
      "\n",
      "         price_ratio  price_pct_change_5  price_pct_change_10  \\\n",
      "17190       1.000108           -0.000537            -0.000427   \n",
      "17193       1.000043            0.000560             0.000648   \n",
      "17194       1.000280           -0.000141             0.002109   \n",
      "17195       1.000453            0.000495             0.001626   \n",
      "17196       1.000438            0.000188            -0.000478   \n",
      "...              ...                 ...                  ...   \n",
      "5237975     1.000117            0.000116             0.000116   \n",
      "5237976     1.000257            0.000514             0.000514   \n",
      "5237977     1.000094           -0.000376            -0.000188   \n",
      "5237978     1.000240            0.000000            -0.000241   \n",
      "5237979     1.000317            0.000316             0.000316   \n",
      "\n",
      "         price_pct_change_30  \n",
      "17190              -0.001177  \n",
      "17193               0.000304  \n",
      "17194               0.003773  \n",
      "17195               0.001646  \n",
      "17196              -0.000331  \n",
      "...                      ...  \n",
      "5237975             0.000755  \n",
      "5237976             0.001180  \n",
      "5237977            -0.004267  \n",
      "5237978             0.002448  \n",
      "5237979            -0.000956  \n",
      "\n",
      "[2213073 rows x 76 columns]\n"
     ]
    }
   ],
   "source": [
    "#time based feature engineering and price based feture engineering .......\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# FUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# FUNCTION TO PERFORM TIME BASED FEATURE ENGINEERING\n",
    "def time_based_features(df):\n",
    "    df['date_id'] = pd.to_datetime(df['date_id'], format='%Y-%m-%d')\n",
    "    df['day_of_week'] = df['date_id'].dt.dayofweek\n",
    "    df['month'] = df['date_id'].dt.month\n",
    "    df['year'] = df['date_id'].dt.year\n",
    "    df['hour_of_day'] = (df['seconds_in_bucket'] / 3600).astype(int)\n",
    "    return df\n",
    "\n",
    "# FUNCTION TO PERFORM PRICE BASED FEATURE ENGINEERING \n",
    "def price_based_features(df):\n",
    "    \n",
    "    # COMPUTE PRICE SPREAD\n",
    "    df['price_spread'] = df['ask_price'] - df['bid_price']\n",
    "    \n",
    "    # COMPUTE PRICE RATIO \n",
    "    df['price_ratio'] = df['ask_price'] / df['bid_price']\n",
    "    \n",
    "    # CALCULATE PERCENTAGE CHANGES IN REFERENCE_PRICE OVER DIFFERENT TIME WINDOW\n",
    "    df['price_pct_change_5'] = df.groupby('stock_id')['reference_price'].pct_change(periods=5)\n",
    "    df['price_pct_change_10'] = df.groupby('stock_id')['reference_price'].pct_change(periods=10)\n",
    "    df['price_pct_change_30'] = df.groupby('stock_id')['reference_price'].pct_change(periods=30)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# DATASET\n",
    "df_train = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\predict us stock price movement compitetion\\train.csv\")\n",
    "\n",
    "#FEATURE \n",
    "columns_to_keep = [\n",
    "    'stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag',\n",
    "    'reference_price', 'matched_size', 'far_price', 'near_price', 'bid_price', 'bid_size',\n",
    "    'ask_price', 'ask_size', 'wap', 'target', 'time_id', 'row_id'\n",
    "]\n",
    "df_train = df_train[columns_to_keep]\n",
    "\n",
    "\n",
    "# DEFINE CATEGORICAL AND NUMERICAL COLUMN\n",
    "categorical_cols = [\n",
    "    'stock_id', 'date_id', 'imbalance_buy_sell_flag', 'time_id', 'row_id'\n",
    "]\n",
    "numerical_cols = [\n",
    "    'seconds_in_bucket', 'imbalance_size', 'reference_price', 'matched_size',\n",
    "    'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'target'\n",
    "]\n",
    "\n",
    "# IDENTIFY MISSING VALUE AND IMPUTE THEM WITH THE MEAN\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_train[['target']] = imputer.fit_transform(df_train[['target']])\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# HANDLE OUTLIERS\n",
    "df_train = handle_outliers(df_train, 'target')\n",
    "\n",
    "# PERFORM TIME BASED FEATURE ENGINEERING \n",
    "df_train = time_based_features(df_train)\n",
    "\n",
    "# PERFORM PRICE BASED FEATURE ENGINEERIGN\n",
    "df_train = price_based_features(df_train)\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# PERFORM BINARY ENCODE FOR CATEGORICAL COLUMN\n",
    "encoder = ce.BinaryEncoder(cols=categorical_cols)\n",
    "df_train_encoded = encoder.fit_transform(df_train)\n",
    "\n",
    "#NORMALIZE AND SCALING \n",
    "scaler_train = StandardScaler()\n",
    "df_train_encoded[numerical_cols] = scaler_train.fit_transform(df_train_encoded[numerical_cols])\n",
    "\n",
    "\n",
    "print(df_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a63cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dad453f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.7754403890740686\n",
      "Mean Squared Error: 0.9802630148621513\n",
      "R-squared: 0.016910856535929497\n"
     ]
    }
   ],
   "source": [
    "#apply linera regression  to Predict US stocks closing movements\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import category_encoders as ce\n",
    "\n",
    "# FUNCTION TO HANDLE OUTLIERS\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# FUNCTION TO PERFORM TIME BASED FEATURE ENGINEERING \n",
    "def time_based_features(df):\n",
    "    df['date_id'] = pd.to_datetime(df['date_id'], format='%Y-%m-%d')\n",
    "    df['day_of_week'] = df['date_id'].dt.dayofweek\n",
    "    df['month'] = df['date_id'].dt.month\n",
    "    df['year'] = df['date_id'].dt.year\n",
    "    df['hour_of_day'] = (df['seconds_in_bucket'] / 3600).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# PERFORM PRICE BASED FEATURE ENGINEERING \n",
    "def price_based_features(df):\n",
    "    \n",
    "    df['price_spread'] = df['ask_price'] - df['bid_price']\n",
    "    \n",
    "    df['price_ratio'] = df['ask_price'] / df['bid_price']\n",
    "   \n",
    "    df['price_pct_change_5'] = df.groupby('stock_id')['reference_price'].pct_change(periods=5)\n",
    "    df['price_pct_change_10'] = df.groupby('stock_id')['reference_price'].pct_change(periods=10)\n",
    "    df['price_pct_change_30'] = df.groupby('stock_id')['reference_price'].pct_change(periods=30)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# DATASET\n",
    "df_train = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\predict us stock price movement compitetion\\train.csv\")\n",
    "\n",
    "# FEATURE \n",
    "columns_to_keep = [\n",
    "    'stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag',\n",
    "    'reference_price', 'matched_size', 'far_price', 'near_price', 'bid_price', 'bid_size',\n",
    "    'ask_price', 'ask_size', 'wap', 'target', 'time_id', 'row_id'\n",
    "]\n",
    "df_train = df_train[columns_to_keep]\n",
    "\n",
    "\n",
    "\n",
    "# DEFINE CATEGORICAL AND NUMERIC COLUMN\n",
    "categorical_cols = [\n",
    "    'stock_id', 'date_id', 'imbalance_buy_sell_flag', 'time_id', 'row_id'\n",
    "]\n",
    "numerical_cols = [\n",
    "    'seconds_in_bucket', 'imbalance_size', 'reference_price', 'matched_size',\n",
    "    'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'target'\n",
    "]\n",
    "\n",
    "# IDENTIFY MISSING VALUES AND IMPUTE WITH MEAN\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_train[['target']] = imputer.fit_transform(df_train[['target']])\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# HANDLE OUTLIERS\n",
    "df_train = handle_outliers(df_train, 'target')\n",
    "\n",
    "# PERFORM TIME BASED FEATURE ENGINEERING \n",
    "df_train = time_based_features(df_train)\n",
    "\n",
    "# PERFORM PRICE BASED FEATURE ENGINEERING \n",
    "df_train = price_based_features(df_train)\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# SPLIT DATA \n",
    "X = df_train_encoded.drop('target', axis=1)\n",
    "y = df_train_encoded['target']\n",
    "\n",
    "# SPLIT DATA INTO TRAING AND TESTING SET \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# TRAIN LINEAR REGRESSION MODEL\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#PREDICTION ON TEST SET \n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# EVALUATE THE MODEL ACCURACY\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e566f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.0169 suggests that your Linear Regression model does not explain much of the variability in the data, \n",
    "#indicating that the model's predictive performance is limited.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5e4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27575bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         stock_id_0  stock_id_1  stock_id_2  stock_id_3  stock_id_4  \\\n",
      "17190             0           0           0           0           0   \n",
      "17193             0           0           0           0           0   \n",
      "17194             0           0           0           0           0   \n",
      "17195             0           0           0           0           0   \n",
      "17196             0           0           0           0           0   \n",
      "...             ...         ...         ...         ...         ...   \n",
      "5237975           0           1           1           1           0   \n",
      "5237976           1           0           0           1           1   \n",
      "5237977           0           1           1           1           0   \n",
      "5237978           0           1           1           1           0   \n",
      "5237979           1           1           0           0           0   \n",
      "\n",
      "         stock_id_5  stock_id_6  stock_id_7  date_id_0  date_id_1  ...  year  \\\n",
      "17190             0           0           1          0          0  ...  1970   \n",
      "17193             0           1           0          0          0  ...  1970   \n",
      "17194             0           1           1          0          0  ...  1970   \n",
      "17195             1           0           0          0          0  ...  1970   \n",
      "17196             1           0           1          0          0  ...  1970   \n",
      "...             ...         ...         ...        ...        ...  ...   ...   \n",
      "5237975           1           0           0          1          1  ...  1970   \n",
      "5237976           1           1           1          1          1  ...  1970   \n",
      "5237977           1           0           1          1          1  ...  1970   \n",
      "5237978           1           1           0          1          1  ...  1970   \n",
      "5237979           1           0           1          1          1  ...  1970   \n",
      "\n",
      "         hour_of_day  price_spread  price_ratio  price_pct_change_5  \\\n",
      "17190              0      0.000108     1.000108           -0.000537   \n",
      "17193              0      0.000043     1.000043            0.000560   \n",
      "17194              0      0.000281     1.000280           -0.000141   \n",
      "17195              0      0.000454     1.000453            0.000495   \n",
      "17196              0      0.000438     1.000438            0.000188   \n",
      "...              ...           ...          ...                 ...   \n",
      "5237975            0      0.000117     1.000117            0.000116   \n",
      "5237976            0      0.000257     1.000257            0.000514   \n",
      "5237977            0      0.000094     1.000094           -0.000376   \n",
      "5237978            0      0.000240     1.000240            0.000000   \n",
      "5237979            0      0.000318     1.000317            0.000316   \n",
      "\n",
      "         price_pct_change_10  price_pct_change_30  volume_spread  \\\n",
      "17190              -0.000427            -0.001177       55133.31   \n",
      "17193               0.000648             0.000304        9301.77   \n",
      "17194               0.002109             0.003773     -156076.98   \n",
      "17195               0.001626             0.001646      -70874.96   \n",
      "17196              -0.000478            -0.000331     -106083.16   \n",
      "...                      ...                  ...            ...   \n",
      "5237975             0.000116             0.000755      287605.36   \n",
      "5237976             0.000514             0.001180     -111715.33   \n",
      "5237977            -0.000188            -0.004267      163247.66   \n",
      "5237978            -0.000241             0.002448      544261.28   \n",
      "5237979             0.000316            -0.000956       50086.12   \n",
      "\n",
      "         volume_ratio  volume_pct_change  \n",
      "17190        3.824221           0.000000  \n",
      "17193        3.353085           0.000000  \n",
      "17194        0.083776           0.000000  \n",
      "17195        0.064132           0.001946  \n",
      "17196        0.026443           0.000000  \n",
      "...               ...                ...  \n",
      "5237975      9.916049           0.000000  \n",
      "5237976      0.455335           0.000000  \n",
      "5237977     10.722528           0.002210  \n",
      "5237978      5.332196           0.000000  \n",
      "5237979      1.200279           0.003974  \n",
      "\n",
      "[2213073 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "#time based feature engineering and price based feture engineering and volumebased feature engineering \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# FUNCTION TO HANDLE OUTLIERS \n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# FUNCTION TO TIME BASED FEATURE ENGINEERING \n",
    "def time_based_features(df):\n",
    "    df['date_id'] = pd.to_datetime(df['date_id'], format='%Y-%m-%d')\n",
    "    df['day_of_week'] = df['date_id'].dt.dayofweek\n",
    "    df['month'] = df['date_id'].dt.month\n",
    "    df['year'] = df['date_id'].dt.year\n",
    "    df['hour_of_day'] = (df['seconds_in_bucket'] / 3600).astype(int)\n",
    "    return df\n",
    "\n",
    "# FUNTION TO PERFORM PRICE BASED FEATURE ENGINNERING \n",
    "def price_based_features(df):\n",
    "  \n",
    "    df['price_spread'] = df['ask_price'] - df['bid_price']\n",
    "    \n",
    "    \n",
    "    df['price_ratio'] = df['ask_price'] / df['bid_price']\n",
    "    \n",
    "    \n",
    "    df['price_pct_change_5'] = df.groupby('stock_id')['reference_price'].pct_change(periods=5)\n",
    "    df['price_pct_change_10'] = df.groupby('stock_id')['reference_price'].pct_change(periods=10)\n",
    "    df['price_pct_change_30'] = df.groupby('stock_id')['reference_price'].pct_change(periods=30)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# FUNCTION TO PERFORM VOLUME BASED FEATURE ENGINEERING \n",
    "def volume_based_features(df):\n",
    "    \n",
    "    #CALCULATE VOLUME SPREAD\n",
    "    df['volume_spread'] = df['ask_size'] - df['bid_size']\n",
    "    \n",
    "    # CALCULATE VOLUME RATIO\n",
    "    df['volume_ratio'] = df['ask_size'] / df['bid_size']\n",
    "    \n",
    "    # CALCULATE THE RATE OF CHANGE IN TRADING VOLUMES\n",
    "    df['volume_pct_change'] = df.groupby('stock_id')['matched_size'].pct_change()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# DATASET\n",
    "df_train = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\predict us stock price movement compitetion\\train.csv\")\n",
    "\n",
    "# FEATURE \n",
    "columns_to_keep = [\n",
    "    'stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag',\n",
    "    'reference_price', 'matched_size', 'far_price', 'near_price', 'bid_price', 'bid_size',\n",
    "    'ask_price', 'ask_size', 'wap', 'target', 'time_id', 'row_id'\n",
    "]\n",
    "df_train = df_train[columns_to_keep]\n",
    "\n",
    "# DEFINE CATEGORICAL AND NUMERIC COLUMN\n",
    "categorical_cols = [\n",
    "    'stock_id', 'date_id', 'imbalance_buy_sell_flag', 'time_id', 'row_id'\n",
    "]\n",
    "numerical_cols = [\n",
    "    'seconds_in_bucket', 'imbalance_size', 'reference_price', 'matched_size',\n",
    "    'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'target'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# IDENTIFY MISSING VALUES ,.....\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_train[['target']] = imputer.fit_transform(df_train[['target']])\n",
    "\n",
    "\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# HANDLE OUTLIERS \n",
    "df_train = handle_outliers(df_train, 'target')\n",
    "\n",
    "\n",
    "\n",
    "# TIME BASED FEATURE ENGINEERING \n",
    "df_train = time_based_features(df_train)\n",
    "\n",
    "\n",
    "\n",
    "# PRICE BASED FEATURE ENGINEERING \n",
    "df_train = price_based_features(df_train)\n",
    "\n",
    "\n",
    "# VOLUME BASED FEATURE ENGINEERING \n",
    "df_train = volume_based_features(df_train)\n",
    "\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# BINARY ENCODE FOR CATEGORICAL COLUMN\n",
    "encoder = ce.BinaryEncoder(cols=categorical_cols)\n",
    "df_train_encoded = encoder.fit_transform(df_train)\n",
    "\n",
    "# NORMALIZE AND SCALING \n",
    "scaler_train = StandardScaler()\n",
    "df_train_encoded[numerical_cols] = scaler_train.fit_transform(df_train_encoded[numerical_cols])\n",
    "\n",
    "\n",
    "print(df_train_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63333438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d915f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         stock_id_0  stock_id_1  stock_id_2  stock_id_3  stock_id_4  \\\n",
      "17190             0           0           0           0           0   \n",
      "17193             0           0           0           0           0   \n",
      "17194             0           0           0           0           0   \n",
      "17195             0           0           0           0           0   \n",
      "17196             0           0           0           0           0   \n",
      "...             ...         ...         ...         ...         ...   \n",
      "5237975           0           1           1           1           0   \n",
      "5237976           1           0           0           1           1   \n",
      "5237977           0           1           1           1           0   \n",
      "5237978           0           1           1           1           0   \n",
      "5237979           1           1           0           0           0   \n",
      "\n",
      "         stock_id_5  stock_id_6  stock_id_7  date_id_0  date_id_1  ...  year  \\\n",
      "17190             0           0           1          0          0  ...  1970   \n",
      "17193             0           1           0          0          0  ...  1970   \n",
      "17194             0           1           1          0          0  ...  1970   \n",
      "17195             1           0           0          0          0  ...  1970   \n",
      "17196             1           0           1          0          0  ...  1970   \n",
      "...             ...         ...         ...        ...        ...  ...   ...   \n",
      "5237975           1           0           0          1          1  ...  1970   \n",
      "5237976           1           1           1          1          1  ...  1970   \n",
      "5237977           1           0           1          1          1  ...  1970   \n",
      "5237978           1           1           0          1          1  ...  1970   \n",
      "5237979           1           0           1          1          1  ...  1970   \n",
      "\n",
      "         hour_of_day  price_spread  price_ratio  price_pct_change_5  \\\n",
      "17190              0      0.000108     1.000108           -0.000537   \n",
      "17193              0      0.000043     1.000043            0.000560   \n",
      "17194              0      0.000281     1.000280           -0.000141   \n",
      "17195              0      0.000454     1.000453            0.000495   \n",
      "17196              0      0.000438     1.000438            0.000188   \n",
      "...              ...           ...          ...                 ...   \n",
      "5237975            0      0.000117     1.000117            0.000116   \n",
      "5237976            0      0.000257     1.000257            0.000514   \n",
      "5237977            0      0.000094     1.000094           -0.000376   \n",
      "5237978            0      0.000240     1.000240            0.000000   \n",
      "5237979            0      0.000318     1.000317            0.000316   \n",
      "\n",
      "         price_pct_change_10  price_pct_change_30  volume_spread  \\\n",
      "17190              -0.000427            -0.001177       55133.31   \n",
      "17193               0.000648             0.000304        9301.77   \n",
      "17194               0.002109             0.003773     -156076.98   \n",
      "17195               0.001626             0.001646      -70874.96   \n",
      "17196              -0.000478            -0.000331     -106083.16   \n",
      "...                      ...                  ...            ...   \n",
      "5237975             0.000116             0.000755      287605.36   \n",
      "5237976             0.000514             0.001180     -111715.33   \n",
      "5237977            -0.000188            -0.004267      163247.66   \n",
      "5237978            -0.000241             0.002448      544261.28   \n",
      "5237979             0.000316            -0.000956       50086.12   \n",
      "\n",
      "         volume_ratio  volume_pct_change  \n",
      "17190        3.824221           0.000000  \n",
      "17193        3.353085           0.000000  \n",
      "17194        0.083776           0.000000  \n",
      "17195        0.064132           0.001946  \n",
      "17196        0.026443           0.000000  \n",
      "...               ...                ...  \n",
      "5237975      9.916049           0.000000  \n",
      "5237976      0.455335           0.000000  \n",
      "5237977     10.722528           0.002210  \n",
      "5237978      5.332196           0.000000  \n",
      "5237979      1.200279           0.003974  \n",
      "\n",
      "[2213073 rows x 79 columns]\n",
      "Decision Tree Regressor Mean Squared Error: 1.8652779760294529\n"
     ]
    }
   ],
   "source": [
    "#PERFORM DECISSION TREE REGRESSOR..........\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# FUNCTION TO HANDLE OUTLIERS \n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# FUNCTION TO PEFORM TIME BASED FEATURE ENGINEERING \n",
    "def time_based_features(df):\n",
    "    df['date_id'] = pd.to_datetime(df['date_id'], format='%Y-%m-%d')\n",
    "    df['day_of_week'] = df['date_id'].dt.dayofweek\n",
    "    df['month'] = df['date_id'].dt.month\n",
    "    df['year'] = df['date_id'].dt.year\n",
    "    df['hour_of_day'] = (df['seconds_in_bucket'] / 3600).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# FUNCTION TO PERFORM PRICE BASED BASED FEATURE ENGINEERING \n",
    "def price_based_features(df):\n",
    "    \n",
    "    df['price_spread'] = df['ask_price'] - df['bid_price']\n",
    "    \n",
    "  \n",
    "    df['price_ratio'] = df['ask_price'] / df['bid_price']\n",
    "    \n",
    "  \n",
    "    df['price_pct_change_5'] = df.groupby('stock_id')['reference_price'].pct_change(periods=5)\n",
    "    df['price_pct_change_10'] = df.groupby('stock_id')['reference_price'].pct_change(periods=10)\n",
    "    df['price_pct_change_30'] = df.groupby('stock_id')['reference_price'].pct_change(periods=30)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# VOLUME BASED FEATURE ENGINEERING \n",
    "def volume_based_features(df):\n",
    "   \n",
    "    df['volume_spread'] = df['ask_size'] - df['bid_size']\n",
    "    \n",
    "   \n",
    "    df['volume_ratio'] = df['ask_size'] / df['bid_size']\n",
    "    \n",
    "  \n",
    "    df['volume_pct_change'] = df.groupby('stock_id')['matched_size'].pct_change()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# FUNCTION TO TRAIN A DECESSION TREE REGRESSOR AND RETURN MEAN SQRD ERROR \n",
    "\n",
    "def train_decision_tree_regression(df):\n",
    "  \n",
    "    X = df.drop(columns=['target'])\n",
    "    y = df['target']\n",
    "    \n",
    "    # SPLIT DATA INTO TRAING AND TESTINFG SET \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    \n",
    "    # TRAIN DECISSION TREE REGRESSOR \n",
    "    clf = DecisionTreeRegressor(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # PREDICT ON THE TEST SET \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # CALCULATE MEAN SQUARD ERROR \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# DATASET\n",
    "df_train = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\predict us stock price movement compitetion\\train.csv\")\n",
    "\n",
    "# FEATURE \n",
    "columns_to_keep = [\n",
    "    'stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag',\n",
    "    'reference_price', 'matched_size', 'far_price', 'near_price', 'bid_price', 'bid_size',\n",
    "    'ask_price', 'ask_size', 'wap', 'target', 'time_id', 'row_id'\n",
    "]\n",
    "df_train = df_train[columns_to_keep]\n",
    "\n",
    "\n",
    "# DEFINE CATEGORICAL AND NUMERICAL COLUMN\n",
    "categorical_cols = [\n",
    "    'stock_id', 'date_id', 'imbalance_buy_sell_flag', 'time_id', 'row_id'\n",
    "]\n",
    "numerical_cols = [\n",
    "    'seconds_in_bucket', 'imbalance_size', 'reference_price', 'matched_size',\n",
    "    'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'target'\n",
    "]\n",
    "\n",
    "# IDENTIFY MISSING VALUES \n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_train[['target']] = imputer.fit_transform(df_train[['target']])\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# HANDLE OUTLIERS \n",
    "df_train = handle_outliers(df_train, 'target')\n",
    "\n",
    "# PERFORM TIME BASED FEATURE ENGINEERING \n",
    "df_train = time_based_features(df_train)\n",
    "\n",
    "# PERFORM PRICE BASED FEATURE ENGINEERING \n",
    "df_train = price_based_features(df_train)\n",
    "\n",
    "# PERFORM VOLUME BASED FEATURE ENGINEERIGN\n",
    "df_train = volume_based_features(df_train)\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# PERFORM BINARY ENCODER FOR CATEGORICAL COLUMN\n",
    "encoder = ce.BinaryEncoder(cols=categorical_cols)\n",
    "df_train_encoded = encoder.fit_transform(df_train)\n",
    "\n",
    "# NORMALIZE AND SCALING \n",
    "scaler_train = StandardScaler()\n",
    "df_train_encoded[numerical_cols] = scaler_train.fit_transform(df_train_encoded[numerical_cols])\n",
    "\n",
    "# TRAIN DECISSION TREE REGRESSOR AND GET MEAN SQUARED ERROR\n",
    "mse = train_decision_tree_regression(df_train_encoded)\n",
    "\n",
    "print(df_train_encoded)\n",
    "\n",
    "\n",
    "print(\"Decision Tree Regressor Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a46e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b61e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         stock_id_0  stock_id_1  stock_id_2  stock_id_3  stock_id_4  \\\n",
      "17190             0           0           0           0           0   \n",
      "17193             0           0           0           0           0   \n",
      "17194             0           0           0           0           0   \n",
      "17195             0           0           0           0           0   \n",
      "17196             0           0           0           0           0   \n",
      "...             ...         ...         ...         ...         ...   \n",
      "5237975           0           1           1           1           0   \n",
      "5237976           1           0           0           1           1   \n",
      "5237977           0           1           1           1           0   \n",
      "5237978           0           1           1           1           0   \n",
      "5237979           1           1           0           0           0   \n",
      "\n",
      "         stock_id_5  stock_id_6  stock_id_7  date_id_0  date_id_1  ...  \\\n",
      "17190             0           0           1          0          0  ...   \n",
      "17193             0           1           0          0          0  ...   \n",
      "17194             0           1           1          0          0  ...   \n",
      "17195             1           0           0          0          0  ...   \n",
      "17196             1           0           1          0          0  ...   \n",
      "...             ...         ...         ...        ...        ...  ...   \n",
      "5237975           1           0           0          1          1  ...   \n",
      "5237976           1           1           1          1          1  ...   \n",
      "5237977           1           0           1          1          1  ...   \n",
      "5237978           1           1           0          1          1  ...   \n",
      "5237979           1           0           1          1          1  ...   \n",
      "\n",
      "         ask_size_skew  ask_size_kurtosis  wap_mean   wap_std  wap_skew  \\\n",
      "17190         5.812111          59.005930  0.999760  0.002024  0.245929   \n",
      "17193         3.601191          23.188927  0.999932  0.001767  0.203647   \n",
      "17194         3.762817          29.972865  0.999808  0.002270  0.150086   \n",
      "17195         8.666756         131.189532  1.000098  0.003244  0.122663   \n",
      "17196         8.266805         180.259819  1.000000  0.002604  0.081008   \n",
      "...                ...                ...       ...       ...       ...   \n",
      "5237975       3.902117          26.244391  0.999835  0.001859  0.029343   \n",
      "5237976       4.058825          38.925640  1.000083  0.002081  0.042728   \n",
      "5237977       4.684289          41.876400  1.000143  0.002840 -0.016020   \n",
      "5237978       2.238794          11.230176  0.999780  0.001939 -0.234773   \n",
      "5237979       2.588014          12.026049  1.000139  0.002594  0.241860   \n",
      "\n",
      "         wap_kurtosis  target_mean  target_std  target_skew  target_kurtosis  \n",
      "17190        1.357923     0.004483    4.697292    -0.003960         0.598757  \n",
      "17193        2.010351    -0.039548    4.254202     0.035377         0.833913  \n",
      "17194        0.734808     0.015267    4.801306     0.008014         0.334634  \n",
      "17195        0.436759    -0.144877    6.592749     0.023737        -0.391420  \n",
      "17196        0.427297    -0.001379    6.684248    -0.013463        -0.470909  \n",
      "...               ...          ...         ...          ...              ...  \n",
      "5237975      0.490419    -0.196839    4.791670    -0.043431         0.474255  \n",
      "5237976      1.093739     0.108207    5.560215    -0.014747         0.021597  \n",
      "5237977      0.460001    -0.001477    6.020380     0.040361        -0.110402  \n",
      "5237978      0.472710    -0.023512    4.560920    -0.126413         0.660428  \n",
      "5237979      1.421768     0.077382    6.355157    -0.000877        -0.264879  \n",
      "\n",
      "[2213073 rows x 144 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "# FUNTION TO HANDLE OUTLIERS \n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# TIME BASED FEATURE ENG..........\n",
    "def time_based_features(df):\n",
    "    df['date_id'] = pd.to_datetime(df['date_id'], format='%Y-%m-%d')\n",
    "    df['day_of_week'] = df['date_id'].dt.dayofweek\n",
    "    df['month'] = df['date_id'].dt.month\n",
    "    df['year'] = df['date_id'].dt.year\n",
    "    df['hour_of_day'] = (df['seconds_in_bucket'] / 3600).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# PRICE BADES FEATURE ENG .........\n",
    "def price_based_features(df):\n",
    "    \n",
    "    df['price_spread'] = df['ask_price'] - df['bid_price']\n",
    "  \n",
    "    df['price_ratio'] = df['ask_price'] / df['bid_price']\n",
    "    \n",
    "    \n",
    "    \n",
    "    df['price_pct_change_5'] = df.groupby('stock_id')['reference_price'].pct_change(periods=5)\n",
    "    df['price_pct_change_10'] = df.groupby('stock_id')['reference_price'].pct_change(periods=10)\n",
    "    df['price_pct_change_30'] = df.groupby('stock_id')['reference_price'].pct_change(periods=30)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# VOLUME BASED FEATURE ENG...\n",
    "def volume_based_features(df):\n",
    "    df['volume_spread'] = df['ask_size'] - df['bid_size']\n",
    "    \n",
    "    df['volume_ratio'] = df['ask_size'] / df['bid_size']\n",
    "    \n",
    "    df['volume_pct_change'] = df.groupby('stock_id')['matched_size'].pct_change()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# PEFORM IMBALANCED BASE FEATURE ENG......\n",
    "def imbalance_features(df):\n",
    "    # CRATE A FEATURE THAT CAPTURE THE RELATIONSHIP BETWEEN imbalance_size AND  imbalance_buy_sell_flag\n",
    "    df['imbalance_relation'] = df['imbalance_size'] * (df['imbalance_buy_sell_flag'] == 'B') - df['imbalance_size'] * (df['imbalance_buy_sell_flag'] == 'S')\n",
    "    \n",
    "    \n",
    "    # COMPUTE COMPULATIVE  IMBALANCE FEATURE OVER TIME \n",
    "    df['cumulative_imbalance_size'] = df.groupby(['stock_id', 'time_id'])['imbalance_size'].cumsum()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# FUNCTION TO PERFORM MOVING AVERAGE  AND EXPONENTIAL MOVING AVERAGE   \n",
    "\n",
    "def moving_averages_ema(df):\n",
    "    \n",
    "    # CALCULATE MOVING AVERAGE  FOR PRICE  AND VOLUME RELATED COLUMNS OVER DIFFERENT TIME WINDOW \n",
    "    windows = [5, 10, 30]  # TIME WINDOW FOR MOVING AVERAGE \n",
    "    for window in windows:\n",
    "        df[f'price_ma_{window}'] = df.groupby('stock_id')['wap'].transform(lambda x: x.rolling(window).mean())\n",
    "        df[f'volume_ma_{window}'] = df.groupby('stock_id')['volume_spread'].transform(lambda x: x.rolling(window).mean())\n",
    "    \n",
    "    # CALCULATE THE EXPONENETIAL MOVING AVERAGE  \n",
    "    alpha = [0.1, 0.2, 0.5]  # ALPHA VALUES FOR EMA \n",
    "    for a in alpha:\n",
    "        df[f'price_ema_{a}'] = df.groupby('stock_id')['wap'].transform(lambda x: x.ewm(alpha=a, adjust=False).mean())\n",
    "        df[f'volume_ema_{a}'] = df.groupby('stock_id')['volume_spread'].transform(lambda x: x.ewm(alpha=a, adjust=False).mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# FUNTION TO PERFORM PRICE TRENDS FEATURE ENGINNERRING \n",
    "def price_trends(df):\n",
    "    periods = [5, 10, 30]  # NUMBER OF PREVIOUS TIME PERIODS\n",
    "    for period in periods:\n",
    "        df[f'price_trend_{period}'] = (df.groupby('stock_id')['reference_price'].shift(0) - df.groupby('stock_id')['reference_price'].shift(period)) > 0\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# FUNTION TO CALCULATE KURTOSIS\n",
    "def calculate_kurtosis(grouped_data):\n",
    "    return grouped_data.kurtosis()\n",
    "\n",
    "# FUNCTION TO CALCULATE STATISTICAL MEATURES\n",
    "def calculate_statistics(df):\n",
    "    # DEFINE NUMERIC COL\n",
    "    numerical_cols = [\n",
    "        'seconds_in_bucket', 'imbalance_size', 'reference_price', 'matched_size',\n",
    "        'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'target'\n",
    "    ]\n",
    "\n",
    "    # CALCULATE STATISTICS FOR EACH NUMERIC COLUMN\n",
    "    for col in numerical_cols:\n",
    "        df[f'{col}_mean'] = df.groupby('stock_id')[col].transform('mean')\n",
    "        df[f'{col}_std'] = df.groupby('stock_id')[col].transform('std')\n",
    "        df[f'{col}_skew'] = df.groupby('stock_id')[col].transform('skew')\n",
    "        df[f'{col}_kurtosis'] = df.groupby('stock_id')[col].transform(calculate_kurtosis)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DATASET\n",
    "df_train = pd.read_csv(r\"C:\\Users\\nh013\\Desktop\\predict us stock price movement compitetion\\train.csv\")\n",
    "\n",
    "# FEATURE \n",
    "columns_to_keep = [\n",
    "    'stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag',\n",
    "    'reference_price', 'matched_size', 'far_price', 'near_price', 'bid_price', 'bid_size',\n",
    "    'ask_price', 'ask_size', 'wap', 'target', 'time_id', 'row_id'\n",
    "]\n",
    "df_train = df_train[columns_to_keep]\n",
    "\n",
    "# DEFINE CATEGORICAL AND NUMERIC COLUMN\n",
    "categorical_cols = [\n",
    "    'stock_id', 'date_id', 'imbalance_buy_sell_flag', 'time_id', 'row_id'\n",
    "]\n",
    "numerical_cols = [\n",
    "    'seconds_in_bucket', 'imbalance_size', 'reference_price', 'matched_size',\n",
    "    'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'target'\n",
    "]\n",
    "\n",
    "#IDENTIFY MISSING VALIES WITH IMPUTE \n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_train[['target']] = imputer.fit_transform(df_train[['target']])\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# HANDLE OUTLIERS \n",
    "df_train = handle_outliers(df_train, 'target')\n",
    "\n",
    "\n",
    "\n",
    "df_train = time_based_features(df_train)\n",
    "df_train = price_based_features(df_train)\n",
    "df_train = volume_based_features(df_train)\n",
    "df_train = imbalance_features(df_train)\n",
    "df_train = moving_averages_ema(df_train)\n",
    "df_train = price_trends(df_train)\n",
    "df_train = calculate_statistics(df_train)\n",
    "\n",
    "\n",
    "# DROP ROWS WITH MISSING VALUES\n",
    "df_train.dropna(inplace=True)\n",
    "\n",
    "# PERFORM BINARY ENCODE FOR CATEGORICAL COL\n",
    "encoder = ce.BinaryEncoder(cols=categorical_cols)\n",
    "df_train_encoded = encoder.fit_transform(df_train)\n",
    "\n",
    "# NORMALIZE AND SCALEING \n",
    "scaler_train = StandardScaler()\n",
    "df_train_encoded[numerical_cols] = scaler_train.fit_transform(df_train_encoded[numerical_cols])\n",
    "\n",
    "print(df_train_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa38ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
